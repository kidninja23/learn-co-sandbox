{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kidninja23/learn-co-sandbox/blob/master/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LBggMPyNmFBL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Jason Bice<br>\n",
        "CS4242 - W01<br>\n",
        "Assignment 3<br>**\n",
        "Problem 1: To implement a perceptron to simulate the function for classifying an image with 2 x 2 pixels as shown in the PPT. Your input will be 16 training examples."
      ]
    },
    {
      "metadata": {
        "id": "0u7zhxmjIHWF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Course: CS4242 W01\n",
        "# Student name: Jason Bice \n",
        "# Student ID: 000248436\n",
        "# Assignment #3 \n",
        "# Due Date: 4/19/19\n",
        "# Signature: Jason Bice\n",
        "# Score:_______________\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib import rcParams\n",
        "#set the plot figure size\n",
        "rcParams[\"figure.figsize\"] = 10, 5\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oxZq73gIItPN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''Class created based on online tutorial materials from pactpub.com, Python Machine learning Part 1'''\n",
        "class Perceptron(object):\n",
        "  '''\n",
        "  Perceptron Classifier.\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  eta : float\n",
        "      Learning rate (between 0.0 and 1.0)\n",
        "  n_iter : int\n",
        "      Passes (epochs) over the training set\n",
        "      \n",
        "      \n",
        "  Attributes\n",
        "  ----------\n",
        "  w_ : id-array\n",
        "      weights after fitting.\n",
        "  errors_ : list\n",
        "      number of misclassification in every epoch\n",
        "  '''\n",
        "  \n",
        "  def __init__(self, eta = 0.01, n_iter = 10):\n",
        "    self.eta = eta\n",
        "    self.n_iter = n_iter\n",
        "    \n",
        "  def fit(self, X, y):\n",
        "    '''\n",
        "    Fit method for training data\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    \n",
        "    X : {array-like}, shape = [n_samples, n_features]\n",
        "        Training vectors, where 'n_samples' is the number \n",
        "        of samples and 'n_features' is the number of features.\n",
        "        \n",
        "    y : {array-like}, shape = [n_samples]\n",
        "        Target value\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    self : object\n",
        "    '''\n",
        "    self.w_ = np.zeros(1 + X.shape[1]) \n",
        "    self.errors_ = [] #initially set as an empty list\n",
        "    \n",
        "    for _ in range(self.n_iter): #_ used becuase the item isn't used\n",
        "      errors = 0 \n",
        "      for xi, target in zip(X, y):\n",
        "        update = self.eta * (target - self.predict(xi))\n",
        "        self.w_[1:] += update * xi\n",
        "        self.w_[0] += update\n",
        "        errors += int(update != 0.0)\n",
        "      self.errors_.append(errors)\n",
        "    return self\n",
        "  \n",
        "  def net_input(self, X):\n",
        "    '''\n",
        "    Calculate the net input\n",
        "    '''\n",
        "    return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "  \n",
        "  def predict(self, X):\n",
        "    '''\n",
        "    Return class lable after unit step\n",
        "    '''\n",
        "    \n",
        "    return np.where(self.net_input(X) >= 0.0, 1, -1)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7AsZesvVN6HQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Data Set was generated in csv format and uploaded directly to the project. The CSV dataset is included with the assignment being turned in. \n",
        "\n",
        "The below code uploads the files directly to colab project. "
      ]
    },
    {
      "metadata": {
        "id": "XdurMlPVhZYd",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "a804c8bd-aae9-4e38-a406-a7a154a78fd4"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cdec8cb4-c4bf-4ce1-bb27-7d418a48c908\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-cdec8cb4-c4bf-4ce1-bb27-7d418a48c908\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Assignment3_dataset.csv to Assignment3_dataset.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3gg6XfSXo5g_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The below code snippet assigns the dataset and then displays the complete dataset. For this data set, each 0 represents a black pixel and each 1 represents a white pixel. Each colum represents one of the 4  individual pixels. Each row is one of the 16 possible unique combinations of  "
      ]
    },
    {
      "metadata": {
        "id": "5eOC06hphmjq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "62f7f58a-6571-4a62-b494-708ec09c3745"
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "df = pd.read_csv(io.BytesIO(uploaded[\"Assignment3_dataset.csv\"]), header = None)\n",
        "df"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Dark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Dark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Bright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Bright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Bright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Bright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Bright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Bright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Bright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bright</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bright</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0  1  2  3       4\n",
              "0   0  0  0  0    Dark\n",
              "1   1  0  0  0    Dark\n",
              "2   0  1  0  0    Dark\n",
              "3   0  0  1  0    Dark\n",
              "4   0  0  0  1    Dark\n",
              "5   1  1  0  0  Bright\n",
              "6   0  1  1  0  Bright\n",
              "7   0  0  1  1  Bright\n",
              "8   1  0  1  0  Bright\n",
              "9   1  0  0  1  Bright\n",
              "10  0  1  0  1  Bright\n",
              "11  1  1  1  0  Bright\n",
              "12  1  0  1  1  Bright\n",
              "13  1  1  0  1  Bright\n",
              "14  0  1  1  1  Bright\n",
              "15  1  1  1  1  Bright"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "wO8uwqMnOhwe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#extract the first 100 class labels, corresponding to the 50 Iris-setosa\n",
        "\n",
        "y = df.iloc[0:, 4].values\n",
        "\n",
        "#np.where(condition[,x,y]) <<--function signature\n",
        "negative_class = -1\n",
        "positive_class = 1\n",
        "condition=y == \"Dark\"\n",
        "y = np.where(condition, \n",
        "             negative_class, \n",
        "             positive_class)\n",
        "\n",
        "X = df.iloc[0:, [0,1,2,3]].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zDoWTVuSjHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training the perceptron in the code below. "
      ]
    },
    {
      "metadata": {
        "id": "KwivGgc9Skcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93f5973e-08a6-4dd6-a6ad-76f727a68d12"
      },
      "cell_type": "code",
      "source": [
        "#instantiate a perceptron object\n",
        "eta = 0.1\n",
        "n_iter = 10 #number of passes over the training data\n",
        "\n",
        "ppn = Perceptron(eta = eta, \n",
        "                 n_iter = n_iter)\n",
        "\n",
        "#fit the perceptron instance to our training data\n",
        "ppn.fit(X,\n",
        "       y)\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Perceptron at 0x7efe745ce3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "metadata": {
        "id": "uuUC9LpHTZHL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the learning process"
      ]
    },
    {
      "metadata": {
        "id": "Xc2RPXYkTX8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "d034a343-069f-42a6-d9b3-f27c1a7783bd"
      },
      "cell_type": "code",
      "source": [
        "#plot the misclassifications\n",
        "epochs = range(1, len(ppn.errors_) + 1)\n",
        "misclassifications=ppn.errors_\n",
        "marker=\"o\"\n",
        "plt.plot(epochs,\n",
        "        misclassifications,\n",
        "        marker=marker)\n",
        "\n",
        "#add labels\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('number of misclassifications')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'number of misclassifications')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzcjBUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "43Fg0ETDpreH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From the above graph we can see that by the sixth pass over the data set, the neuarl network no longer has any error in predicting if a set should be classified as Dark or Bright. The 16 datapoints represent the entire set of possible outcomes, so any consideration of overfitting the data is not relevant. "
      ]
    },
    {
      "metadata": {
        "id": "J9bq1W39DbWj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Problem 2: Implement a multi-layer feedforward back-propagation algorithm (we can just call it ANN) that can “Teach a Neural Network for Classification”. <br>Requirements:<br>\n",
        "1) You must have three layers (input, hidden, and output) in your architecture.<br>\n",
        "2) Use Sigmoid function as your transfer function.<br>\n",
        "Implement the ANN to recognize 4 blocks image (such as one image shown below) to make a decision if an image is BRIGHT or DARK. Remember that we have 16 samples for the input. You must have at least three layers in your ANN: input layer, hidden layer, and output layer.\n",
        "\n",
        "Problem 2 will use the same dataset configuration as problem 1."
      ]
    },
    {
      "metadata": {
        "id": "imFQHLSqZ5OF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "seed(42)\n",
        "  \n",
        "def generate_network(feat, hidden, outs):\n",
        "    neural_net = []\n",
        "    h_layer = generate_weights(feat, hidden)\n",
        "    o_layer = generate_weights(hidden, outs)\n",
        "    neural_net.append(h_layer)\n",
        "    neural_net.append(o_layer)\n",
        "    return neural_net\n",
        "    \n",
        "  #generates all weights needed for each feature of a dataset and a bias weight at weights[-1]\n",
        "def generate_weights(r1, r2):\n",
        "    w = [ {'weights' : [random() - 0.5 for i in range(r1 + 1)]} for i in range(r2)]\n",
        "    return w\n",
        "  \n",
        "  #Calcualte the weighted sums that will be used for propagating through the network\n",
        "def weighted_sums(weights, input_vals):\n",
        "    sums = weights[-1] #initial sum value set to the bias value\n",
        "    for i in range(len(weights) - 1):\n",
        "      sums += weights[i] * input_vals[i]\n",
        "    return sums\n",
        "  \n",
        "  #defining the sigmoid function \n",
        "def sigmoid(sum_vals):\n",
        "    s = 1.0/(1.0 + math.exp(-sum_vals))\n",
        "    return s\n",
        "    \n",
        "  #defining sigmoid prime function\n",
        "def sigmoid_prime(s):\n",
        "    s_prime = s * (1.0 - s)\n",
        "    return s_prime\n",
        "  \n",
        "  #Forward propagation through the neural network\n",
        "def f_prop(network, row):\n",
        "    vals = row\n",
        "    for layers in network:\n",
        "      new_vals = []\n",
        "      for node in layers:\n",
        "        the_sums = weighted_sums(node['weights'], vals)\n",
        "        node['output'] = sigmoid(the_sums)\n",
        "        new_vals.append(node['output'])\n",
        "      vals = new_vals\n",
        "    return vals\n",
        "  \n",
        "  #Backward propagation through the neural network\n",
        "def b_prop(network, expected_vals):\n",
        "    for i in reversed(range(len(network))):\n",
        "      l = network[i]\n",
        "      errors = []\n",
        "      if i != len(network) - 1:\n",
        "        for j in range(len(l)):\n",
        "          error = 0.0\n",
        "          for node in network[i + 1]:\n",
        "            error += (node['weights'][j] * node['delta'])\n",
        "          errors.append(error)\n",
        "      else: \n",
        "          for j in range(len(l)):\n",
        "            node = l[j]\n",
        "            errors.append(expected_vals[j] - node['output'])\n",
        "      for j in range(len(l)):\n",
        "          node = l[j]\n",
        "          node['delta'] = errors[j] * sigmoid_prime(node['output'])\n",
        "  #Calculate the weights and assign them for the next pass through the neural network        \n",
        "def new_weight(network, row, rate):\n",
        "    for i in range(len(network)):\n",
        "      inputs = row[:-1]\n",
        "      if i != 0:\n",
        "        inputs = [node['output'] for node in network[i - 1]]\n",
        "      for node in network[i]:\n",
        "        for j in range(len(inputs)):\n",
        "          node['weights'][j] += rate * node['delta'] * inputs[j]\n",
        "        node['weights'][-1] += rate * node['delta']\n",
        "   #train the network to assign the correct weights.        \n",
        "def training(network, dataset, rate, epochs, outputs, print_op = 0):\n",
        "    for epoch in range(epochs):\n",
        "      total_error = 0\n",
        "      for row in dataset:\n",
        "        outs = f_prop(network, row)\n",
        "        target = [0 for i in range(outputs)]\n",
        "        target[row[-1]] = 1\n",
        "        total_error += sum([(target[i] - outs[i])**2 for i in range(len(target))])\n",
        "        b_prop(network, target)\n",
        "        new_weight(network, row, rate)\n",
        "      if print_op != 0:\n",
        "        print('>epoch=%d, rate=%.3f, error=%.3f' % (epoch, rate, total_error))\n",
        "  \n",
        "def prediction(network,row):\n",
        "    outputs = f_prop(network, row)\n",
        "    return outputs.index(max(outputs))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6d52RrBvTIQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "4c826010-ff38-4a9f-9f0c-88794252c48f"
      },
      "cell_type": "code",
      "source": [
        "dataset = [[0,0,0,0,0],\n",
        "\t        [1,0,0,0,0],\n",
        "          [0,1,0,0,0],\n",
        "          [0,0,0,1,0],\n",
        "          [1,1,0,0,1],\n",
        "          [0,1,1,0,1],\n",
        "          [0,0,1,1,1],\n",
        "          [1,0,1,0,1],\n",
        "          [1,0,0,1,1],\n",
        "          [0,1,0,1,1],\n",
        "          [1,1,1,0,1],\n",
        "          [1,0,1,1,1],\n",
        "          [1,1,0,1,1],\n",
        "          [0,1,1,1,1],\n",
        "          [1,1,1,1,1]]\n",
        "\n",
        "\n",
        "n_inputs = len(dataset[0]) - 1\n",
        "n_outputs = len(set([row[-1] for row in dataset]))\n",
        "network = generate_network(n_inputs, 2, n_outputs)\n",
        "training(network, dataset, 0.1, 25, n_outputs, 1)\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">epoch=0, rate=0.100, error=6.785\n",
            ">epoch=1, rate=0.100, error=6.590\n",
            ">epoch=2, rate=0.100, error=6.441\n",
            ">epoch=3, rate=0.100, error=6.327\n",
            ">epoch=4, rate=0.100, error=6.240\n",
            ">epoch=5, rate=0.100, error=6.172\n",
            ">epoch=6, rate=0.100, error=6.120\n",
            ">epoch=7, rate=0.100, error=6.080\n",
            ">epoch=8, rate=0.100, error=6.047\n",
            ">epoch=9, rate=0.100, error=6.022\n",
            ">epoch=10, rate=0.100, error=6.001\n",
            ">epoch=11, rate=0.100, error=5.984\n",
            ">epoch=12, rate=0.100, error=5.970\n",
            ">epoch=13, rate=0.100, error=5.959\n",
            ">epoch=14, rate=0.100, error=5.949\n",
            ">epoch=15, rate=0.100, error=5.941\n",
            ">epoch=16, rate=0.100, error=5.934\n",
            ">epoch=17, rate=0.100, error=5.928\n",
            ">epoch=18, rate=0.100, error=5.923\n",
            ">epoch=19, rate=0.100, error=5.918\n",
            ">epoch=20, rate=0.100, error=5.914\n",
            ">epoch=21, rate=0.100, error=5.910\n",
            ">epoch=22, rate=0.100, error=5.907\n",
            ">epoch=23, rate=0.100, error=5.903\n",
            ">epoch=24, rate=0.100, error=5.900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "my1wanLsgJFb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can clearly see that the error is decreasing over each epoch. Twentyfive passes is not quite enough to train the network to acurately make predictions yet. The next section of code increases the epoch value to 200 and forgoes printing each epoch. We then make a prediction based on all rows of the data set. "
      ]
    },
    {
      "metadata": {
        "id": "gcJA7WFwEG5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "79e7cbab-2428-4944-9d73-e4f231825e9f"
      },
      "cell_type": "code",
      "source": [
        "training(network, dataset, 0.1, 200, n_outputs, 0)\n",
        "\n",
        "for row in dataset:\n",
        "\tresults = prediction(network, row)\n",
        "\tprint('Expected=%d, Got=%d' % (row[-1], results))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expected=0, Got=0\n",
            "Expected=0, Got=0\n",
            "Expected=0, Got=0\n",
            "Expected=0, Got=0\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n",
            "Expected=1, Got=1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ODdLe3wDizI5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At this point, ANN can succesfully predict any of the 16 possible pixel combinations and classify them as Dark (0) or Bright(1).<br> The only that ANN doesn't do yet is accept the data as an actual block of pixels. The next part will add this functionality. "
      ]
    },
    {
      "metadata": {
        "id": "WGB2387JjRgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}